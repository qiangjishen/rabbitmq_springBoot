package cn.cnnic.data.center.controller;

import com.google.common.collect.Lists;
import lombok.extern.slf4j.Slf4j;
import org.apache.dubbo.common.utils.CollectionUtils;
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.common.TopicPartition;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.kafka.config.KafkaListenerEndpointRegistry;
import org.springframework.kafka.core.ConsumerFactory;
import org.springframework.scheduling.annotation.Scheduled;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;

import java.util.List;
import java.util.Properties;

@RestController
@RequestMapping("/kafka")
@Slf4j
public class KafkaConsumerController {

    /**
     * @KafkaListeneræ³¨è§£æ‰€æ ‡æ³¨çš„æ–¹æ³•å¹¶ä¸ä¼šåœ¨IOCå®¹å™¨ä¸­è¢«æ³¨å†Œä¸ºBeanï¼Œ
     * è€Œæ˜¯ä¼šè¢«æ³¨å†Œåœ¨KafkaListenerEndpointRegistryä¸­ï¼Œ
     * è€ŒKafkaListenerEndpointRegistryåœ¨SpringIOCä¸­å·²ç»è¢«æ³¨å†Œä¸ºBean
     **/
    @Autowired
    private KafkaListenerEndpointRegistry registry;

    @Autowired
    private ConsumerFactory consumerFactory;


    @GetMapping("/start")
    public String startConsume() {
        //åˆ›å»ºkafka consumer
        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(buildKafkaConfig());
        try {

            String topic = "topic.hangge.demo";

            int partitionIndex = 0;
            //å£°æ˜kafkaåˆ†åŒºæ•°ç›¸ç­‰çš„æ¶ˆè´¹çº¿ç¨‹æ•°ï¼Œä¸€ä¸ªåˆ†åŒºå¯¹åº”ä¸€ä¸ªæ¶ˆè´¹çº¿ç¨‹
            int consumeThreadNum = 9;
            //ç‰¹æ®ŠæŒ‡å®šæ¯ä¸ªåˆ†åŒºå¼€å§‹æ¶ˆè´¹çš„offset
            List<Integer> partitionOffsets = Lists.newArrayList(106, 0, 0, 0, 0, 0, 0, 0, 0);

            //æŒ‡å®šè¯¥consumerå¯¹åº”çš„æ¶ˆè´¹åˆ†åŒº
            TopicPartition partition = new TopicPartition(topic, partitionIndex);
            consumer.assign(Lists.newArrayList(partition));

            //consumerçš„offsetå¤„ç†
            if (CollectionUtils.isNotEmpty(partitionOffsets)  &&  partitionOffsets.size() == consumeThreadNum) {
                Integer seekOffset = partitionOffsets.get(partitionIndex);
                log.info("partition:{} , offset seek from {}", partition, seekOffset);
                consumer.seek(partition, seekOffset);

            }

            //å¼€å§‹æ¶ˆè´¹æ•°æ®ä»»åŠ¡
            kafkaRecordConsume(consumer, partition);
        } catch (Exception e) {
            log.error("kafka consume error:{}", e.getStackTrace());
        } finally {
            try {
                consumer.commitSync();
            } finally {
                consumer.close();
            }
        }

        return "success";
    }


    private void kafkaRecordConsume(KafkaConsumer<String, String> consumer, TopicPartition partition) {
        while (true) {
            try {
                ConsumerRecords<String, String> records = consumer.poll(3000);
                //å…·ä½“çš„å¤„ç†æµç¨‹
                records.forEach((k) -> handleKafkaInput(k.key(), k.value()));

                //ğŸŒ¿å¾ˆé‡è¦ï¼šæ—¥å¿—è®°å½•å½“å‰consumerçš„offsetï¼Œpartitionç›¸å…³ä¿¡æ¯(ä¹‹åå¦‚éœ€é‡æ–°æŒ‡å®šoffsetæ¶ˆè´¹å°±ä»è¿™é‡Œçš„æ—¥å¿—ä¸­è·å–offsetï¼Œpartitionä¿¡æ¯)
                if (records.count() > 0) {
                    String currentOffset = String.valueOf(consumer.position(partition));
                    log.info("current records size isï¼š{}, partition is: {}, offset is:{}", records.count(), consumer.assignment(), currentOffset);
                }

                //offsetæäº¤, offsetä¿å­˜åˆ°æ•°æ®åº“ï¼Œæ”¾åˆ°åŒä¸€ä¸ªäº‹åŠ¡ä¸­ã€‚
                consumer.commitAsync();
            } catch (Exception e) {
                log.error("handlerKafkaInput error{}", e.getStackTrace());
            }
        }
    }

    public  void handleKafkaInput(String key, String value ) {
        log.info("key--->{}", key);
        log.info("value--->{}", value);
    }


    /**
     * å£°æ˜kafka consumerçš„é…ç½®ç±»
     * @return
     */
    private Properties buildKafkaConfig() {
        Properties kafkaConfiguration = new Properties();
        kafkaConfiguration.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "192.168.81.133:9092");
        kafkaConfiguration.put(ConsumerConfig.GROUP_ID_CONFIG, "");
        kafkaConfiguration.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, "5");
        //  kafkaConfiguration.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, "");
        kafkaConfiguration.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, "org.apache.kafka.common.serialization.StringDeserializer");
        kafkaConfiguration.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, "org.apache.kafka.common.serialization.StringDeserializer");
        kafkaConfiguration.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG,"earliest");
        kafkaConfiguration.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, "false");


        return kafkaConfiguration;
    }



    /**
     * å®šæ—¶å¯åŠ¨ç›‘å¬å™¨
     * @param
     * @author yh
     * @date 2022/5/11
     * @return
     */
    @GetMapping("/startListener")
    public void startListener() {

        System.out.println("-->"+registry.getListenerContainer("demoContainer3").isRunning());
        System.out.println(registry.getListenerContainer("demoContainer3").isContainerPaused());

        // "timingConsumer"æ˜¯@KafkaListeneræ³¨è§£åé¢è®¾ç½®çš„ç›‘å¬å™¨ID,æ ‡è¯†è¿™ä¸ªç›‘å¬å™¨
        if (!registry.getListenerContainer("demoContainer3").isRunning() ) {
            registry.getListenerContainer("demoContainer3").start();
        }
        if ( registry.getListenerContainer("demoContainer3").isContainerPaused()) {
            registry.getListenerContainer("demoContainer3").resume();
        }
        //registry.getListenerContainer("timingConsumer").resume();
    }

    /**
     * å®šæ—¶åœæ­¢ç›‘å¬å™¨
     * @param
     * @author yh
     * @date 2022/5/11
     * @return
     */
    @GetMapping("/stop")
    public void shutDownListener() {

        registry.getListenerContainer("demoContainer3").pause();
    }


}
